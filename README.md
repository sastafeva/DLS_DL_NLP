# Школа глубокого обучения ФПМИ МФТИ
Выполнение заданий DLS (МФТИ). 2 семестр. NLP with Pytorch.

В этом репозитории выложены домашние задания, выполненные мной в процессе прохождения курса по NLP-задачам.

Архитектуры нейронных сетей реализованы на фреймворке Pytorch.

## Домашние задания

## [01W_Simple_embeddings](01W_Simple_embeddings)
Основы Natural Language Processing и классических методов классификации текста.

В домашнем задании предлагалось решить задачу ранжирования вопросов с помощью библиотек nltk и spacy

## [02W_Embeddings](02W_Embeddings)
Разновидности эмбеддингов.

В домашнем задании предлагалось решить задачу семантической классификации текстов твитов.

## [03W_RNN](03W_RNN)
Рекуррентные нейронные сети.

В домашнем задании предлагалось решить задачу классификации комментариев к фильмам с сайта IMDB с помощью RNN и CNN.

## [04W_Language_Model](04W_Language_Model)
Языковые модели.

В домашнем задании предлагалось решить задачу определения части речи различными способами.

## [05W_Seq2Seq](05W_Seq2Seq)
Машинный перевод.

В домашнем задании предлагалось реализовать модель машинного перевода с использованием архитектуры RNN (GRU, LSTM), а также, реализовать Attention слой для декодера.

## [06W_Transformers](06W_Transformers)
Трансформеры и их разновидности.

Домашнее задание состояло из 2-х частей:
- Анализ сентимента с помощью GPT-2 и исследования карт Attention
- Анализ сентимента с помощью BERT

## [07W_Summarization](07W_Summarization)
Суммаризация текста.

В домашнем задании предлагалось решить задачу генерации "сжатых" новостей.

## [08W_Audio](08W_Audio)
Введение в обработку звука.

В домашнем задании предлагалось построить классификатор для определения возраста спикера в датасете Timits.
Я попробовала 2 реализации: 
- с помощью библиотеки librosa, которая предлагалась в задании.
- переписала предобработку на pytorch с добавлением аугментации.